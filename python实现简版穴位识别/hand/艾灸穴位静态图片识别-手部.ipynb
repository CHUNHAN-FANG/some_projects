{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import dlib\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用标注好的xml 训练svm分类器\n",
    "faces_folder = \"./handpredictor\"\n",
    "#“handdetector.svm”为已训练好的，如果存在择不用再训练\n",
    "if not os.path.exists(\"handdetector.svm\"):\n",
    "    options = dlib.simple_object_detector_training_options()#//设置训练参数\n",
    "    options.add_left_right_image_flips = True\n",
    "    options.C = 5\n",
    "    options.num_threads = 4\n",
    "    options.be_verbose = True\n",
    "\n",
    "    training_xml_path = os.path.join(faces_folder, \"handsdata.xml\")#训练数据集\n",
    "    testing_xml_path = os.path.join(faces_folder, \"test.xml\")#测试数据集\n",
    "    dlib.train_simple_object_detector(training_xml_path, \"handdetector.svm\", options)#生成检测器“handdetector.svm”\n",
    "\n",
    "    print(\"\")  # Print blank line to create gap from previous output\n",
    "    print(\"Training accuracy: {}\".format(\n",
    "    dlib.test_simple_object_detector(training_xml_path, \"handdetector.svm\")))\n",
    "    print(\"Testing accuracy: {}\".format(\n",
    "    dlib.test_simple_object_detector(testing_xml_path, \"handdetector.svm\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目标检测 测试\n",
    "detector = dlib.simple_object_detector(\"handdetector.svm\")#加载检测器\n",
    "'''\n",
    "# We can look at the HOG filter we learned.  It should look like a face.  Neat!\n",
    "win_det = dlib.image_window()\n",
    "win_det.set_image(detector)\n",
    "'''\n",
    "# Now let's run the detector over the images in the faces folder and display the\n",
    "# results.\n",
    "print(\"Showing detections on the images in the faces folder...\")\n",
    "win = dlib.image_window()\n",
    "#测试“testimages”目录下的所有jpg文件\n",
    "for f in glob.glob(os.path.join(faces_folder, \"test/*.jpg\")):\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    img = dlib.load_rgb_image(f)\n",
    "    dets = detector(img)\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "    for k, d in enumerate(dets):\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "\n",
    "    win.clear_overlay()\n",
    "    win.set_image(img)\n",
    "    win.add_overlay(dets)\n",
    "    dlib.hit_enter_to_continue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_folder = \"./handpredictor\"\n",
    "#“handpredictor.dat”为已训练好的，如果存在择不用再训练\n",
    "if not os.path.exists(\"handpredictor.dat\"):\n",
    "    options = dlib.shape_predictor_training_options()\n",
    "    #现在让对象负责训练模型。\n",
    "    #这个算法有很多参数，你可以搞砸。这个documentation for the shape_predictor_trainer的文档解释了所有这些。\n",
    "    #您还应该阅读Kazemi的论文，其中解释了所有参数非常详细。但是，这里我只设置其中的三个与默认值不同\n",
    "    #我这么做是因为我们有一个非常小的数据集。特别地，设置过采样\n",
    "    #到较高的数量（300）有效地提高了训练集的大小，所以\n",
    "    #这有助于这个示例。\n",
    "\n",
    "    #通过对训练样本进行随机变形扩大样本数目。比如你原来有N张训练图片，通过该参数的设置，训练样本数将变成N*_oversampling_amount张。\n",
    "    #所以通常该值越大越好，只是训练耗时也会越久\n",
    "    options.oversampling_amount = 100\n",
    "    #我还通过显式增加来减少模型的容量\n",
    "    #正则化（使nu更小）以及使用较小的深度。\n",
    "    #正则项，nu越大，表示对训练样本fit越好，当然也越有可能发生过拟合。_nu取值范围(0,1]，默认取0.1。\n",
    "    options.nu = 0.05\n",
    "    #树深，则树的叶子节点个数为2(_tree_depth)个\n",
    "    options.tree_depth = 4\n",
    "    #cpu测试机器为num_threads(线程)核数\n",
    "    options.num_threads=8\n",
    "    options.be_verbose = True\n",
    "\n",
    "    #dlib.train_shape_predictor() 执行实际的训练。输入是一个XML文件，它列出了训练数据集中的图像\n",
    "    #并且还包含人脸的位置部分零件。\n",
    "    training_xml_path = os.path.join(faces_folder, \"handsdata.xml\")\n",
    "    #它将保存final predictor to handpredictor.dat.\n",
    "    dlib.train_shape_predictor(training_xml_path, \"handpredictor.dat\", options)\n",
    "\n",
    "# 现在我们有了一个模型，可以测试它了 dlib.test_shape_predictor()\n",
    "# measures the average distance between a face landmark output by the\n",
    "# shape_predictor and where it should be according to the truth data.\n",
    "    print(\"\\nTraining accuracy: {}\".format(\n",
    "        dlib.test_shape_predictor(training_xml_path, \"handpredictor.dat\")))\n",
    "        # 真正的测试是看它在没有经过训练的数据上表现得有多好。\n",
    "        #我们在一个非常小的数据集上训练它，所以精度不是很高。\n",
    "        #但是它仍然做得很好. 此外，如果你在一个大型飞机上训练\n",
    "        # 面部标志数据集，您将获得最先进的结果, 如Kazemi论文所示.\n",
    "    testing_xml_path = os.path.join(faces_folder, \"test.xml\")\n",
    "    print(\"Testing accuracy: {}\".format(\n",
    "        dlib.test_shape_predictor(testing_xml_path, \"handpredictor.dat\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2ImgAddText(img,text,left, top, textColor=(0, 255, 0), textSize=20):\n",
    "    if (isinstance(img, np.ndarray)):  #判断是否OpenCV图片类型\n",
    "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    fontText = ImageFont.truetype(\"font/simsun.ttc\", textSize, encoding=\"utf-8\")\n",
    "    draw.text((left, top), text, textColor, font=fontText)\n",
    "    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "# 现在让我们像在普通应用程序中一样使用它.  首先，我们将从磁盘加载它。\n",
    "# 我们还需要加载一个面部检测器来提供初始值面部位置的估计。\n",
    "predictor = dlib.shape_predictor(\"handpredictor.dat\")\n",
    "#detector = dlib.get_frontal_face_detector()\n",
    "#加载之前训练好的目标检测器\n",
    "detector = dlib.simple_object_detector(\"handdetector.svm\")############################\n",
    "\n",
    "\n",
    "#现在让我们在面部的图像上运行检测器和shape_predictor文件夹并显示结果。\n",
    "#print(\"Showing detections and predictions on the images in the faces folder...\")\n",
    "win = dlib.image_window()\n",
    "for f in glob.glob(os.path.join(faces_folder, \"test/*.jpg\")):\n",
    "    #print(\"Processing file: {}\".format(f))\n",
    "    img = dlib.load_rgb_image(f)\n",
    "    #img = dlib.load_rgb_image(os.path.join(faces_folder, \"handimages/S1-P1-F-11-1.jpg\"))\n",
    "\n",
    "    # 让探测器找出每个人脸的边框。 The 1 in the\n",
    "    # 第二个参数指示我们应该对图像进行1次上采样. \n",
    "    #这将使所有东西变得更大，并允许我们检测更多的脸。\n",
    "    #dets = detector(img, 1)\n",
    "    dets = detector(img)\n",
    "    #d=dlib.rectangle(114, 140, 355, 388)\n",
    "    #print(\"Left: {} Top: {} Right: {} Bottom: {}\".format(d.left(), d.top(), d.right(), d.bottom()))\n",
    "    # Get the landmarks/parts for the face in box d.\n",
    "    for d in dets:\n",
    "        shape = predictor(img, d)\n",
    "        cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        #特征点总数\n",
    "        partss=len(shape.parts())\n",
    "        Li=[\"十宣穴1\",\"十宣穴2\",\"十宣穴3\",\"十宣穴4\",\"十宣穴5\",\"少府穴\",\"劳宫穴\",\"鱼际穴\"]        \n",
    "        for i in range(8):\n",
    "            name = Li[i]\n",
    "            pa=shape.part(i)\n",
    "            p = (pa.x,pa.y)\n",
    "#             #(shape.part(i).x, shape.part(i).y)\n",
    "#             cv2.circle(img,p,2,(0,255,0),2)\n",
    "#             #各参数依次是：照片/添加的文字/左上角坐标/字体/字体大小/颜色/字体粗细\n",
    "#             #cv2.putText(img,name,p,cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),1)\n",
    "#             frame =cv2ImgAddText(img,name,p,cv2.FONT_HERSHEY_SIMPLEX,(255,255,0), 12)\n",
    "            \n",
    "            cv2.circle(img, p, 5, color=(0,255, 0))\n",
    "            # 利用cv2.putText输出1-68\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            img =cv2ImgAddText(img,name,pa.x,pa.y,(0,0,0),40)\n",
    "                    \n",
    "                    \n",
    "    # Draw the face landmarks on the screen.\n",
    "    cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    win.clear_overlay()\n",
    "    win.set_image(img)\n",
    "    #win.add_overlay(shape)\n",
    "    win.add_overlay(d)\n",
    "    dlib.hit_enter_to_continue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
